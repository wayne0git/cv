{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask R-CNN & GrabCut Example \n",
    "- Ref : https://www.pyimagesearch.com/2020/09/28/image-segmentation-with-mask-r-cnn-grabcut-and-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow\n",
    "- 1. Computes pixel-wise segmentation mask for each object in the input image based on Mask R-CNN (Tensorflow)\n",
    "- 2. Applies GrabCut to the object via the mask to improve the image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter -- Input Files\n",
    "IMG_PATH = 'example.jpg'\n",
    "IMG_RESIZE_WIDTH = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter -- Mask R-CNN\n",
    "MODEL_PATH = 'mask-rcnn-coco'\n",
    "MODEL_LABEL_PATH = os.path.join(MODEL_PATH, 'object_detection_classes_coco.txt')\n",
    "MODEL_PB_PATH = os.path.join(MODEL_PATH, 'frozen_inference_graph.pb')\n",
    "MODEL_PBTXT_PATH = os.path.join(MODEL_PATH, 'mask_rcnn_inception_v2_coco_2018_01_28.pbtxt')\\\n",
    "\n",
    "USE_GPU = True\n",
    "CONF_TH = 0.5    # Object Detection Threshold\n",
    "MIN_SEG_TH = 0   # Minimum Threshold Pixel-Wise Mask Segmentation\n",
    "OUT_NODES = ['detection_out_final', 'detection_masks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter -- GrabCut\n",
    "ITER = 10                    # Grabcut Iteration\n",
    "MODE = cv2.GC_INIT_WITH_MASK # Grabcut mode (GC_INIT_WITH_RECT / GC_INIT_WITH_MASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabcut Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabcut_seg_mask(img, mask_init):\n",
    "    # Allocate memory for Grabcut\n",
    "    mask = np.zeros(img.shape[:2], dtype='uint8')  # Output mask\n",
    "    bg_model = np.zeros((1, 65), dtype='float')    # Internal use\n",
    "    fg_model = np.zeros((1, 65), dtype='float')    # Internal use\n",
    "\n",
    "    # Convert to Grabcut mask value\n",
    "    mask[mask_init > 0] = cv2.GC_PR_FGD\n",
    "    mask[mask_init == 0] = cv2.GC_BGD\n",
    "\n",
    "    # Grabcut Segmentation\n",
    "    mask, bg_model, fg_model = cv2.grabCut(img, mask, None, bg_model, fg_model, ITER, MODE)     \n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMG_PATH)\n",
    "img = imutils.resize(img, width=IMG_RESIZE_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO label (90 class names)\n",
    "labels = open(MODEL_LABEL_PATH).read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mask R-CNN model\n",
    "net = cv2.dnn.readNetFromTensorflow(MODEL_PB_PATH, MODEL_PBTXT_PATH)\n",
    "if USE_GPU:\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# boxes -- (1, 1, #Objects, 7). For each object => (X, ClassID, Confidence, x0_n, y0_n, x1_n, y1_n)\n",
    "# masks -- (#Objects, #Class, 15, 15)\n",
    "blob = cv2.dnn.blobFromImage(img, swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "boxes, masks = net.forward(OUT_NODES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each object\n",
    "cv2.namedWindow('Result', cv2.WINDOW_NORMAL)\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "for i in range(boxes.shape[2]):\n",
    "    # Extract Class ID & its Confidence\n",
    "    class_id = int(boxes[0, 0, i, 1])\n",
    "    conf = boxes[0, 0, i, 2]\n",
    "\n",
    "    # Confidence Threshold\n",
    "    if conf > CONF_TH:\n",
    "        # Extract bounding box\n",
    "        box = boxes[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        x0, y0, x1, y1 = box.astype(np.int)\n",
    "        bh, bw = y1 - y0, x1 - x0\n",
    "\n",
    "        # Extract & Resize Pixel-Wise Mask\n",
    "        mask = masks[i, class_id]\n",
    "        mask = cv2.resize(mask, (bw, bh), interpolation=cv2.INTER_CUBIC)\n",
    "        mask = (mask > MIN_SEG_TH).astype(np.uint8) * 255\n",
    "\n",
    "        # Mask R-CNN Result\n",
    "        rcnn_mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "        rcnn_mask[y0:y1, x0:x1] = mask\n",
    "        rcnn_out = cv2.bitwise_and(img, img, mask=rcnn_mask)\n",
    "\n",
    "        # Apply Grabcut\n",
    "        # Set Definite / Propable BG to 0 and Definite / Propable FG to 1        \n",
    "        grab_mask = grabcut_seg_mask(img, rcnn_mask.copy())\n",
    "        grab_mask = np.where((grab_mask == cv2.GC_BGD) | (grab_mask == cv2.GC_PR_BGD), 0, 1)\n",
    "\n",
    "        # Grabcut Result\n",
    "        grab_out = cv2.bitwise_and(img, img, mask=(grab_mask * 255).astype('uint8'))        \n",
    "\n",
    "        # Show Result\n",
    "        cv2.setWindowTitle('Result', labels[class_id])\n",
    "        cv2.imshow('Result', np.hstack([img, rcnn_out, grab_out]))\n",
    "        if cv2.waitKey(0) == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
